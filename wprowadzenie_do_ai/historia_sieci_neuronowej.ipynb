{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mG1j3RziALvU",
   "metadata": {
    "id": "mG1j3RziALvU"
   },
   "source": [
    "# Z historii AI - sztuczny neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UNEsjd-pZ1WW",
   "metadata": {
    "id": "UNEsjd-pZ1WW"
   },
   "source": [
    "## Lata 40 XX w."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imn0tczdAaxJ",
   "metadata": {
    "id": "imn0tczdAaxJ"
   },
   "source": [
    "### M. Minsky i S. Papert o latach 40 XX w.\n",
    "\n",
    "- “<span t=\"q\">W latach czterdziestych XX wieku pojawiła się prosta, ale potężna koncepcja, że naturalnymi składnikami maszyn podobnych do umysłu są proste abstrakcje oparte na zachowaniu biologicznych komórek nerwowych i że takie maszyny można zbudować poprzez połączenie takich elementów.</span>”\n",
    "\n",
    "- Najważniejsze wydarzenia:\n",
    "  - <span t=\"l1\">1943 - Warren Sturgis McCulloch i Walter Pitts, A Logical Calculus of Ideas Immanent in Nervous Activity</span> <span t=\"l2\">dyskusja na temat „sieci neurologicznych”, w której połączyli nowe idee dotyczące maszyn skończonych, elementów decyzyjnych z liniowym progiem i logicznymi reprezentacjami różnych form zachowania i pamięci</span>\n",
    "\n",
    "  - <span t=\"l1\">1947 - Warren Sturgis McCulloch i Walter Pitts, How we know universals the perception of auditory and visual forms</span>\n",
    "opis architektury sieciowej zdolnej w zasadzie do rozpoznawania wzorców przestrzennych w sposób niezmienny w grupach przekształceń geometrycznych.\n",
    "Powstanie cybernetyki\n",
    "próbowała połączyć wiele pojęć z biologii, psychologii, inżynierii i matematyki. Era cybernetyki spowodowała powódź schematów architektonicznych, dzięki którym sieci neuronowe mogą rozpoznawać, śledzić, zapamiętywać i wykonywać wiele innych przydatnych funkcji.\n",
    "\n",
    "  - 1949 - Donald Hebb, The Organization of Behavior\n",
    "pierwsza próby oparcia wielkoskalowej teorii psychologii na przypuszczeniach dotyczących sieci neuronowych. Główną ideą książki Hebba było to, że takie sieci mogą uczyć się, konstruując wewnętrzne reprezentacje pojęć w formie tego, co Hebb nazywał „zespołami komórkowymi” – podrodzinami neuronów, które nauczyły się wspierać nawzajem. Wcześniej podejmowano próby wyjaśnienia psychologii w kategoriach “połączeń” lub „powiązań”, ale (być może dlatego, że te powiązania były jedynie między symbolami lub ideami, a nie między mechanizmami) te teorie wydawały się wtedy zbyt nieistotne, by mogły być traktowane poważnie przez teoretyków poszukujących modeli dla mechanizmów psychicznych.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p2yl0KGpayPk",
   "metadata": {
    "id": "p2yl0KGpayPk"
   },
   "source": [
    "### Pierwszy model sztucznego neuronu (1943)\n",
    "\n",
    "<img src=\"../pliki_z_internetu/McCulloch_Pitts.png\" align=\"right\"/>\n",
    "\n",
    "- W 1943 roku dwaj amerykanie, neurofizjolog i cybernetyk Warren Sturgis McCulloch oraz logik Walter Pitts w artykule pt. A Logical Calculus of Ideas Immanent in Nervous Activity zaproponowali pierwszy model sztucznego neuronu, znany dziś jako neuron McCullocha–Pittsa, w skrócie neuron MCP. \n",
    "- Jak się dziś uważa, był to pierwszy wynik badań wpisujący się w dziedzinę sztucznej inteligencji, której powstanie datuje się na ponad dekadę później. \n",
    "\n",
    "Model neuronu MCP ma dwa główne źródła inspiracji: \n",
    "- budowę i sposób działania neuronu biologicznego oraz \n",
    "- dwuwartościowy, „zero-jedynkowy”, logiczny rachunek zdań.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OdZo48fkejom",
   "metadata": {
    "id": "OdZo48fkejom"
   },
   "source": [
    "### Budowa neuronu (koniec XIX w.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493aecd3",
   "metadata": {},
   "source": [
    "### Bartolomeo Camillo Emilio Golgi\n",
    "\n",
    "<img src=\"../pliki_z_internetu/1024px-Camillo_Golgi.jpg\" align=\"left\" alt=\"Bartolomeo Camillo Emilio Golgi\" width=\"300\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f384ec",
   "metadata": {},
   "source": [
    "### Santiago Ramón y Cajal\n",
    "<img src=\"../pliki_z_internetu/Cajal-Restored.jpg\" align=\"left\" alt=\"Santiago Ramón y Cajal\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e033d2",
   "metadata": {},
   "source": [
    "### Rysunki Cajala\n",
    "<img src=\"../pliki_z_internetu/Cajal_cortex_drawings.png\" align=\"left\" alt=\"Cajal cortex drawings\" width=\"360\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heVlokwygv6v",
   "metadata": {
    "id": "heVlokwygv6v"
   },
   "source": [
    "### Budowa neuronu\n",
    "\n",
    "<img src=\"../pliki_z_internetu/1280px-Neuron-LangNeutral.svg.png\" align=\"right\" alt=\"budowa neuronu\" width=\"700\">\n",
    "\n",
    "Schemat budowy neuronu: \n",
    "- a – dendryty, \n",
    "- b – ciało komórki, \n",
    "- c – jądro komórkowe, \n",
    "- d – akson, \n",
    "- e – otoczka mielinowa, \n",
    "- f – komórka Schwanna, \n",
    "- g – przewężenie Ranviera, \n",
    "- h – zakończenia aksonu\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08480d",
   "metadata": {},
   "source": [
    "<continue/>\n",
    "Neuron (inaczej komórka nerwowa) jest komórką ciała zdolną do odbierania, przetwarzania i przekazywania informacji w postaci sygnału elektrycznego. \n",
    "Neuron odbiera bodźce za pomocą **synaps** znajdujących się w **dendrytach**. \n",
    "Neuron może posiadać jeden lub więcej dendrytów i odbierać nawet tysiące sygnałów jednocześnie. \n",
    "Sygnały ze wszystkich dendrytów są przekazywane dalej do **somy**, ciała komórki. \n",
    "Gdy sygnał docierający do neuronu ze wszystkich dendrytów jest dostatecznie silny, tj. gdy suma wszystkich bodźców odbieranych przez dendryty i przesłanych do ciała komórki przekroczy pewien próg, na początkowym odcinku **aksonu** powstaje potencjał czynnościowy. \n",
    "Dochodzi  do ,,rozbłyśnięcia'' neuronu, czyli powstania sygnału elektrycznego, który rozprzestrzenia się w dół wzdłuż aksonu do synaps znajdujących się na jego zakończeniach. Neurony posiadają zwykle jeden akson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tDdSAgrdhObd",
   "metadata": {
    "id": "tDdSAgrdhObd"
   },
   "source": [
    "### Zasada „wszystko albo nic”\n",
    "\n",
    "<img src=\"https://registeredalien.weebly.com/uploads/4/4/1/5/4415448/1370578357.png\" align=\"right\" alt=\"Principia  mathematica\" width=\"400\">\n",
    "\n",
    "- Przewodzenie sygnałów przez neuron podlega zasadzie wszystko albo nic, tzn. neuron wytwarza potencjał czynnościowy lub go nie wytwarza. \n",
    "- McCulloch i Pitts, inspirując się klasycznym rachunkiem zdań:\n",
    "  - wytworzenie sygnału przez neuron oznaczyli przez 1, a brak sygnału przez 0,\n",
    "  - przyjęli, że sygnały wchodzące do neuronu mogą mieć wartość 1 albo 0\n",
    "  - neuron sumuje sygnały i porównuje tę sumę z „progiem”, którego przekroczenie gwarantuje wytworzenie przez neuron sygnału (tj. zwrócenie wartości 1). \n",
    "\n",
    "???:\n",
    "- Przewodzenie sygnałów przez neuron podlega zasadzie wszystko albo nic („The Activity of the neuron is an „all-or-one” process.”, s. 101) tzn. neuron wytwarza potencjał czynnościowy lub go nie wytwarza. \n",
    "- Inspirując się dwuwartościowym (0-1) logicznym rachunkiem zdań, McCulloch i Pitts wytworzenie sygnału przez neuron oznaczyli przez 1, a brak sygnału przez 0. \n",
    "- Dodatkowo McCulloch i Pitts założyli, że sygnały wchodzące do neuronu mogą być pobudzające lub hamujące. Pobudzające mają wartość 1 a hamujące 0. \n",
    "- Ściślej rzecz ujmując, założyli oni, że jeśli choć jeden z sygnałów wchodzących do neuronu jest hamujący (tj. ma wartość 0), to nie dochodzi do pobudzenia neuronu (komentarz). Natomiast jeśli wszystkie impulsy są pobudzające (tj. mają wartość 1), to neuron sumuje je i porównuje tę sumę z „progiem”, którego przekroczenie gwarantuje wytworzenie przez neuron sygnału (tj. zwrócenie wartości 1). \n",
    "- Większa suma bodźców nie prowadzi do wytwarzania silniejszego sygnału. Wynik jest zawsze binarny (0-1), tj. albo sygnał jest albo go nie ma; tertium non datur, jak głosi fundamentalna zasada logiki dwuwartościowej.\n",
    "- Uogólniając sposób działania neuronu możemy więc potraktować go jako bardzo prosty system na wejściu którego mamy n sygnałów, które następnie są sumowane i jeśli ta suma przekroczy próg, na wyjściu mamy sygnał (1), w przeciwnym razie - brak sygnału (0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X_lvN4YIiz3t",
   "metadata": {
    "id": "X_lvN4YIiz3t"
   },
   "source": [
    "### Definicje funktorów logicznych\n",
    "\n",
    "Neuron MCP można łatwo użyć do zdefiniowania funktorów logicznych. Na przykład alternatywa …\n",
    "\n",
    "- $g(f(x,y)) = 1$, jeśli $f(x,y) \\geq 1$\n",
    "- $g(f(x,y)) = 0$, jeśli $f(x,y) = 0$\n",
    "- $f(x,y) = x + y$\n",
    "\n",
    "Okazuje się, że neuron MCP może reprezentować jedynie funktory KRZ, które mają tę własność, że ich przedstawienie graficzne pozwala na oddzielenie linią prostą lub płaszczyzną wartości dla których funktor przyjmuje wartość 1 od tych dla których przyjmuje wartość 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HEnGXxR_kHOI",
   "metadata": {
    "id": "HEnGXxR_kHOI"
   },
   "source": [
    "### Ważenie sygnałów - Hebbian learning (1949)\n",
    "\n",
    "<img src=\"https://www.fruitsinfo.com/psychegames.com/responsive/imgs/doanldhebb.JPG\" align=\"right\" alt=\"Donald Olding Hebb\n",
    "\" width=\"300\">\n",
    "\n",
    "Pomysł na uczący się neuron pochodzi od kanadyjskiego psychologa Donalda Oldinga Hebba, który w 1949, w pracy The Organization of Behaviour, zaprezentował swój pomysł znany dziś pod nazwą Hebbian learning. \n",
    "Nie wszystkie dendryty są sobie równe. \n",
    "Neuron jest bardziej „wrażliwy” na sygnały przychodzące przez pewne dendryty niż inne, więc do powstania potencjału czynnościowego aksonu potrzeba mniej sygnału na tych ścieżkach.\n",
    "Pomysł, że neurony przy „podejmowaniu decyzji\" o powstania sygnału elektrycznego „ważą” przychodzące sygnały. Neuron będzie dynamicznie zmieniać te wagi w procesie podejmowania decyzji w trakcie swojego życia.\n",
    "Hebb zasugerował, że w neuronie może zachodzie następujący proces: \n",
    "jeśli jakiś sygnał dość często przyczynia się do wytworzenia przez neuron impulsu, wówczas zachodzi pewne zmiana w tym neuronie, która sprawia, że zwiększa się łatwość z jaką ten sygnał pobudza neuron. \n",
    "Proces zmiany wag nie został uwzględniony w modelu neuronu MCP.\n",
    "Pomysł Hebba zastosowany do neuronu MCP: każdy sygnał wchodzący do neuronu “ważymy” poprzez przemnożenie wartości tego sygnału przez wagę w.\n",
    "\n",
    "\n",
    "Ważenie sygnałów - Hebbian learning (1949)\n",
    "\n",
    "Nie wszystkie dendryty są sobie równe. Komórka jest bardziej „wrażliwa” na sygnały przychodzące przez pewne dendryty niż inne, więc do powstania potencjału czynnościowego aksonu potrzeba mniej sygnału na tych ścieżkach.\n",
    "Kluczową koncepcją, na którą należy zwrócić uwagę, jest sposób, w jaki komórki ważą przychodzące sygnały przy „podejmowaniu decyzji\" o powstania sygnału elektrycznego. Neuron będzie dynamicznie zmieniać te wagi w procesie podejmowania decyzji w trakcie swojego życia.\n",
    "Proces zmiany wag nie został uwzględniony w modelu neuronu MCP. Stąd też neuron ten nie uczył się. \n",
    "Pomysł na uczący się neuron pochodzi od kanadyjskiego psychologa Donalda Hebba, który w 1949, w pracy The Organization of Behaviour, zaprezentował swój pomysł znany dziś pod nazwą Hebbian learning. \n",
    "Hebb zasugerował mianowicie, że w neuronie może zachodzie następujący proces: jeśli jakiś sygnał dość często przyczynia się do wytworzenia przez neuron impulsu, wówczas zachodzi pewne zmiana w tym neuronie, która sprawia, że zwiększa się łatwość z jaką ten sygnał pobudza neuron. \n",
    "Pomysł Hebba zastosowany do neuronu MCP wyglądałby tak, że każdy sygnał wchodzący do neuronu „ważylibyśmy” poprzez przemnożenie wartości tego sygnału przez wagę w.\n",
    "Inspiracje Pawłovem i reinforcement learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7HSBXdW3k5eM",
   "metadata": {
    "id": "7HSBXdW3k5eM"
   },
   "source": [
    "### Perceptron, czyli neuron uczy się\n",
    "\n",
    "Sieci neuronów mogą uczyć się, konstruując wewnętrzne reprezentacje pojęć w formie „zespołów komórkowych”, które nauczyły się wspierać nawzajem.\n",
    "$g(x_1, x_2, …, x_n) = w_1*x_1 + w_2*x_2 +…+ w_n*x_n$\n",
    "\n",
    "$y = f(g(x1, x2, …, xn)) = 1$, jeśli \n",
    "$w1*x1 + w2*x2 +…+ wn*xn \\geq wartość\\_progu$\n",
    "\n",
    "$y = f(g(x1, x2, …, xn)) = 0$, jeśli\n",
    "$w1*x1 + w2*x2 +…+ wn*xn < wartość\\_progu$\n",
    "\n",
    "$y = f(g(x1, x2, …, xn)) = 1$, jeśli \n",
    "$w1*x1 + w2*x2 +…+ wn*xn - wartość_progu \\geq 0$\n",
    "$y = f(g(x1, x2, …, xn)) = 0$, jeśli\n",
    "$w1*x1 + w2*x2 +…+ wn*xn - wartość_progu < 0$\n",
    "\n",
    "RYSUNEK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0572fc2",
   "metadata": {},
   "source": [
    "## Perceptron, czyli neuron uczy się"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CafBh1dvJwac",
   "metadata": {
    "id": "CafBh1dvJwac"
   },
   "source": [
    "### Perceptron, czyli neuron uczy się\n",
    "\n",
    "Aby neuron mógł się uczyć musi mieć materiał do nauki i nauczyciela.\n",
    "\n",
    "|       | przykład 1 | przykład 2 | przykład 3 | przykład 4 |\n",
    "|:-----:|:----------:|:----------:|:----------:|:----------:|\n",
    "| $x_1$ |      0     |      1     |      0     |      1     |\n",
    "| $x_1$ |      0     |      0     |      1     |      1     |\n",
    "|  $y$  |      0     |      1     |      1     |      1     |\n",
    "\n",
    "\n",
    "- Neuron uczy się poprzez zmianę wag.\n",
    "- Musi mieć odpowiednią funkcję aktywacji.\n",
    "\n",
    "RYSUNEK\n",
    "\n",
    "$y’ = f(g(x1, x2, …, xn))  = 1$, jeśli \n",
    "$g(x1, x2, …, xn) - wartość\\_progu \\geq 0.5$\n",
    "\n",
    "$y’ = f(g(x1, x2, …, xn))  = 0$, jeśli\n",
    "$g(x1, x2, …, xn) - wartość\\_progu < 0.5$\n",
    "\n",
    "jeżeli $y’ ≠ y$, to $w_i = w_i + y*x_i$\n",
    "\n",
    "- w1 = 0, w2 = 0, w_p = 0\n",
    "\n",
    "przykład 1\n",
    "g(0, 0) = 0*0 + 0*0 + 0 = 0\n",
    "y’ = 0\n",
    "w1 = 0, w2 = 0, w_p = 0\n",
    "\n",
    "przykład 2\n",
    "g(1, 0) = 0*1 + 0*0 + 0 = 0\n",
    "y’ = 0\n",
    "w1 = 1, w2 = 0, w_p = 0\n",
    "\n",
    "przykład 3\n",
    "g(0, 1) = 1*0 + 0*1 + 0 = 0\n",
    "y’ = 0\n",
    "w1 = 1, w2 = 1, w_p = 0\n",
    "\n",
    "przykład 4\n",
    "g(1, 1) = 1*1 + 1*1 + 0 = 2\n",
    "y’ = 1\n",
    "w1 = 1, w2 = 1, w_p = 0\n",
    "\n",
    "przykład 1\n",
    "g(0, 0) = 1*0 + 1*0 + 0 = 0\n",
    "y’ = 0\n",
    "w1 = 1, w2 = 1, w_p = 0\n",
    "\n",
    "przykład 2\n",
    "g(1, 0) = 1*1 + 1*0 + 0 = 1\n",
    "y’ = 1\n",
    "w1 = 1, w2 = 1, w_p = 0\n",
    "\n",
    "przykład 3\n",
    "g(0, 1) = 1*0 + 1*1 + 0 = 1\n",
    "y’ = 1\n",
    "w1 = 1, w2 = 1, w_p = 0\n",
    "\n",
    "przykład 4\n",
    "g(1, 1) = 1*1 + 1*1 + 0 = 2\n",
    "y’ = 1\n",
    "w1 = 1, w2 = 1, w_p = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gQBoiiZGKmhK",
   "metadata": {
    "id": "gQBoiiZGKmhK"
   },
   "source": [
    "## **Lata 50 XX w.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0qqohxmDLdw9",
   "metadata": {
    "id": "0qqohxmDLdw9"
   },
   "source": [
    "### M. Minsky i S. Papert o latach 50 XX w.\n",
    "\n",
    "- “Era cybernetyki otworzyła perspektywę tworzenia maszyn podobnych do umysłu. Najwcześniejsi pracownicy w tej dziedzinie poszukiwali konkretnych architektur, które mogłyby pełnić określone funkcje. Jednak ze względu na fakt, że zwierzęta mogą nauczyć się wielu rzeczy, do których nie zostały stworzone, wkrótce cel zmienił się w tworzenie maszyn, które mogłyby się uczyć.”\n",
    "- “Pojęcie uczenia się jest źle zdefiniowane, ponieważ nie ma wyraźnej granicy między najprostszymi formami pamięci a złożonymi procedurami przewidywania i uogólniania rzeczy, których nigdy nie widziano. Większość wczesnych eksperymentów opierała się na pomyśle „wzmacniania” działań, które odniosły sukces w przeszłości – koncepcji popularnej już w psychologii behawiorystycznej. W celu zastosowania wzmocnienia do systemu, system musi być w stanie wygenerować wystarczającą różnorodność działań do wyboru, a system potrzebuje jakiegoś kryterium względnego sukcesu.”\n",
    "- Najważniejsze wydarzenia:\n",
    "  - 1951 - SNARC, Minsky\n",
    "“Składał się z czterdziestu jednostek elektronicznych połączonych siecią łączy, z których każdy miał regulowane prawdopodobieństwo odbierania sygnałów aktywacyjnych, a następnie przesyłania ich do innych jednostek. Uczył się za pomocą procesu wzmacniania, w którym każda pozytywna lub negatywna ocena zachowania maszyny przekładała się na niewielką zmianę (odpowiedniej wielkości i znaku) prawdopodobieństw związanych z dowolnymi połączeniami, które ostatnio przesłały sygnały. W latach pięćdziesiątych pojawiło się wiele innych systemów, które wykorzystywały proste formy uczenia się, co doprowadziło do powstania specjalizacji zawodowej zwanej kontrolą adaptacyjną (adaptive control).” \n",
    "  - 1958 - Perceptron (MARK I), Rosenblatt (ale to jeszcze na komputerze pierwszej generacji)\n",
    "  - Powstała druga generacja komputerów (zobacz Tadeusiewicz)\n",
    "  - Jednak dostępność komputerów otworzyła również inne drogi badań nad uczeniem się. Być może najbardziej godnym uwagi tego przykładem były badania Arthura Samuela dotyczące programowania komputerów do nauki gry w warcaby. (Patrz Uwagi bibliograficzne.) Korzystając z systemu nagród opartego na sukcesie, programy Samuela z lat 1959 i 1967 osiągnęły mistrzowskie poziomy wydajności. Rozwijając te procedury, Samuel napotkał i opisał dwa fundamentalne pytania (Minsky nie wierzy, że są ogólne rozwiązania możliwe, aby na nie odpowiedzić):\n",
    "Przydzielenie nagrody (credit). Biorąc pod uwagę niektóre istniejące składniki, w jaki sposób można zdecydować, ile przypisać każdemu z nich (składników) za każde z osiągnięć maszyny? W maszynie Samuela wagi są przypisywane przez korelację z sukcesem.\n",
    "Wymyślanie nowych predykatów. Jeśli istniejące składniki są niewystarczające, jak wymyślić nowe? Maszyna Samuela testuje produkty pod pewnymi wcześniej istniejącymi warunkami.\n",
    "“Większość badaczy próbowała ominąć te pytania, ignorując je, używając brutalnej siły lub próbując odkryć potężne i ogólnie możliwe do zastosowania metody. Niewielu badaczy próbowało wykorzystać je jako przewodniki po przemyślanych badaniach. Nie wierzymy, że może istnieć jakiekolwiek całkowicie ogólne rozwiązanie ich problemu, i w naszym epilogu argumentujemy, że świadomość tych problemów powinna prowadzić do modelu umysłu, który może kumulować wielość wyspecjalizowanych metod.”\n",
    "- Pod koniec lat pięćdziesiątych dziedzina badań sieci neuronowych była praktycznie uśpiona. Po części było tak dlatego, że przez długi czas nie było wielu ważnych odkryć. Ale po części było tak również dlatego, że dokonano ważnych postępów w sztucznej inteligencji dzięki wykorzystaniu nowych rodzajów modeli opartych na seryjnym przetwarzaniu wyrażeń symbolicznych. Pojawiły się nowe punkty orientacyjne w postaci działających programów komputerowych, które rozwiązywały stosunkowo trudne problemy. W następstwie tych osiągnięć teorie oparte na powiązaniach między symbolami nagle stały się bardziej satysfakcjonujące. I chociaż my i niektórzy inni utrzymywaliśmy wierność obu podejściom, intelektualne linie frontu zaczęły formować się na takich frontach pojęciowych, jak przetwarzanie równoległe i szeregowe, uczenie się i programowanie oraz wyłanianie się (emergence) i opis analityczny.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E5HgEzcnLzAu",
   "metadata": {
    "id": "E5HgEzcnLzAu"
   },
   "source": [
    "### Pierwsza samoucząca się maszyna (1951)\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/waYt6fGyayE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "\n",
    "- Pierwszą samouczącą się maszynę skonstruowali studenci Uniwersytetu Harwarda: Marvin Lee Minsky\n",
    "i Dean Edmonds\n",
    "- Nazwa: Stochastic Neural Analog Reinforcement Calculator, w skrócie SNARC\n",
    "- Inspiracja: reinforcement learning; Skinner\n",
    "SNARC składał się z czterdziestu neuronów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v88HhPE8bnZg",
   "metadata": {
    "id": "v88HhPE8bnZg"
   },
   "source": [
    "<continue/>\n",
    "\n",
    "<img src=\"https://cdn.the-scientist.com/assets/articleNo/65792/hImg/31709/the-scientist-foundations-original-the-first-artifical-intelligence-x.webp\" align=\"right\" alt=\"Neuron SNARCa\" width=\"600\">\n",
    "\n",
    "Czerwony element po lewej: Pamięć krótkotrwała: kondensator. \n",
    "Jeśli sygnał przejdzie, ten kondensator zapamiętuje to przez kilka sekund.\n",
    "\n",
    "Wystający element po prawej: Pamięć długotrwała: potencjometr. Prawdopodobieństwo, że jeśli sygnał wejdzie na jedno z tych wejść, inny sygnał wyjdzie z wyjścia. Prawdopodobieństwo, że tak się stanie, waha się od 0, jeśli ten potencjometr jest ściszony, do 1, jeśli jest maksymalnie odkręcony.\n",
    "\n",
    "\n",
    "Proces uczenia: łańcuch i sprzęgło.\n",
    "Jeśli 40 neuronów 20 przewodziło impulsy i stało się coś, co oczekiwaliśmy, naciskamy przycisk, aby nagrodzić maszynę. Uruchamia się duży silnik, a do wszystkich 40 tych potencjometrów jest łańcuch, a pomiędzy nimi znajduje się sprzęgło magnetyczne. Czyli jeśli to przewodzi, jeśli ten neuron rzeczywiście przesłał impuls i ten kondensator to pamięta, to sprzęgło będzie załączone i gdy duży łańcuch przejdzie przez te wszystkie rzeczy, to te, które niedawno odpaliły, poruszą się trochę i trochę jego ruch będzie zależeć od tego, jak dawno temu zadziałał, ponieważ ładunek tego kondensatora jest zależny od czasu, a po naładowaniu kondensatora prąd przepływa przez ten rezystor i spływa. Minsky i Edmonds przetestowali jego możliwości uczenia się, każąc maszynie poruszać się po wirtualnym labiryncie. Kiedy podjęto działanie, które zaowocowało pozytywną nagrodą, sprzęgło elektryczne zostało użyte do włączenia ruchomego łańcucha, który obracał potencjometr. Połączona sieć ustawień potencjometrów (analogicznie do wag w dzisiejszych całkowicie cyfrowych sieciach neuronowych) była w stanie nauczyć się działań mających na celu rozwiązanie labiryntu.\n",
    "\n",
    "<img src=\"https://historyof.ai/assets/images/snarc/snarc_with_chain.jpg\" align=\"right\" alt=\"Neuron SNARCa z łańcuchem\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7OztRiDPcMYi",
   "metadata": {
    "id": "7OztRiDPcMYi"
   },
   "source": [
    "### Perceptron (1958)\n",
    "\n",
    "- Frank Rosenblatt\n",
    "- Mark I Perceptron\n",
    "\n",
    "<img src=\"https://news.cornell.edu/sites/default/files/styles/story_thumbnail_xlarge/public/2019-09/0925_rosenblatt_main.jpg?itok=SE0aS7ds\" align=\"right\" alt=\"Frank Rosenblatt\" width=\"600\">\n",
    "\n",
    "<img src=\"https://news.cornell.edu/sites/default/files/styles/breakout/public/2019-09/0925_rosenblatt5.jpg?itok=nuD-Y14c\" align=\"right\" alt=\"Frank Rosenblatt\" width=\"600\">\n",
    "\n",
    "Pierwszy perceptron został zaprojektowany do rozpoznawania obrazów o rozmiarze 20 x 20 pikseli. Był konglomeratem fotodetektorów i potencjometrów. W jego skład wchodziła siatka 400 fotodetektorów (tj. czujników przetwarzających światło na sygnały elektryczne). \n",
    "Każdy z 400 fotodekoderów ,,obserwował’’ (tj. reagowała na) jeden z 400 (20∗20) pikseli obrazu. \n",
    "Jasność obrazu, którą mógłby ,,zobaczyć’’ określony fotodekoder, przekładała się na siłę sygnału, którą wysyłał. Sygnały były ,,ważone’’, tj. każdemu z nich przypisane została waga za pomocą potencjometra (aktualizacje wagi podczas uczenia były wykonywane przez silniki elektryczne). \n",
    "Gdy gdy suma sygnałów ze wszystkich potencjometrów przekroczyła pewien próg, perceptron wysyłał sygnał elektryczny, wskazując na pozytywne dopasowanie na przedstawionym mu obrazie. Jeśli dla danego obrazu nie doszło do pobudzenia, był to negatywny wynik klasyfikacji.\n",
    "\n",
    "<img src=\"https://news.cornell.edu/sites/default/files/styles/full_size/public/2019-09/0925_rosenblatt2.jpg?itok=Vx8qs4Ic\" align=\"right\" alt=\"Inteligent automation\" width=\"600\">\n",
    "\n",
    "\n",
    "Frank Rosenblatt, Principles of Neurodynamics\n",
    "\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/cNxadbrN_aI\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ky6VAknjdiET",
   "metadata": {
    "id": "ky6VAknjdiET"
   },
   "source": [
    "## **Lata 60 XX w.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x3BUxHX0drcc",
   "metadata": {
    "id": "x3BUxHX0drcc"
   },
   "source": [
    "### Perceptrons (1969)\n",
    "\n",
    "<img src=\"https://mitpress.mit.edu/sites/default/files/styles/large_book_cover/http/mitp-content-server.mit.edu%3A18180/books/covers/cover/%3Fcollid%3Dbooks_covers_0%26isbn%3D9780262534772%26type%3D.jpg?itok=eARg-HSE\" align=\"right\" alt=\"Inteligent automation\" width=\"300\">\n",
    "\n",
    "- Minsky i Papert\n",
    "- 1970 Turing Award\n",
    "- convergence theorem 11.1\n",
    "- No machine can learn to recognize X unless it possesses, at least potentially, some scheme for representing» X.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852e0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ai_neuron.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
