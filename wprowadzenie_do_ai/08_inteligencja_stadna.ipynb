{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6780779c",
   "metadata": {},
   "source": [
    "# Inteligencja stadna (grupowa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dccc40c",
   "metadata": {},
   "source": [
    "### Inteligencja stadna \n",
    "\n",
    "Inteligencja stadna (grupowa) (ang. swarm intelligence) – podejście do obliczeń oparte o samoorganizującą się populację autonomicznych jednostek oddziałujących na siebie oraz na środowisko, w którym się znajdują.\n",
    "Inteligencja stadna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7ee2e",
   "metadata": {},
   "source": [
    "## Algorytmy mrówkowe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69898aec",
   "metadata": {},
   "source": [
    "### Algorytmy mrówkowe \n",
    "\n",
    "Algorytmy mrówkowe zostały opracowane przez Marco Dorigo.\n",
    "\n",
    "W algorytmach mrówkowych autonomicznymi jednostkami są sztuczne mrówki, które szukając rozwiązań w przestrzeni rozwiązań pozostawiają ślad feromonowy.\n",
    "\n",
    "Dla obiecujących miejsc w przestrzeni rozwiązań następuje wzrost natężenia feromonu.\n",
    "\n",
    "Dla miejsc w przestrzeni rozwiązań o niskiej jakości natężenia feromonu maleją."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bfd2c1",
   "metadata": {},
   "source": [
    "### Grupowanie danych – podstawowe założenia\n",
    "\n",
    "Podstawowym zadaniem grupowania (klasteryzacji) jest dokonanie podziału zbioru przypadków C znajdujących się w bazie na grupy $C_1, C_2, ..., C_k$, nazywane klastrami,\n",
    "stanowiące podzbiory przypadków podobnych do siebie, przy czym pojęcie podobieństwa może być definiowane w różny sposób.\n",
    "\n",
    "Podział zbioru $C$ powinien być dokonany w taki sposób, aby przypadki z danej grupy były bardziej podobne do siebie (homogeniczność) niż do jakichkolwiek przypadków z pozostałych grup (heterogeniczność)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f59cb0",
   "metadata": {},
   "source": [
    "W wielu sytuacjach przypadki grupowane są razem ze względu na istniejące pomiędzy nimi zależności takie jak np. noeodróżnialność, podobieństwo, bliskość, funkcjonalność, zgodność.\n",
    "\n",
    "Podobieństwo przypadków może być definiowane na różne sposoby, zależnie od typu grupowanych danych. Bardzo często jako miarę podobieństwa wykorzystuje się odległość pomiędzy przypadkami w przestrzeni, w której rozważane są przypadki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c156a955",
   "metadata": {},
   "source": [
    "### Miary odległości\n",
    "\n",
    "<span t=\"l1\">Dane są dwa punkty x oraz y w przestrzeni m- wymiarowej:</span>\n",
    "\n",
    "<span t=\"l2\">$x=[x_1, x_2, ...,x_m]$ </span>\n",
    "\n",
    "<span t=\"l2\">$y=[y_1, y_2 ,..., y_m]$</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdbec23",
   "metadata": {},
   "source": [
    "<span t=\"l1\">Odległość (metryka) Euklidesa</span>\n",
    "\n",
    "<span t=\"l2\">$ d_{Eukl}(x,y)=\\sqrt{\\sum_{i=1}^{n} (y_i-x_i)^2  } $</span>\n",
    "\n",
    "<span t=\"l1\">Odległość (metryka) Manhattanu</span>\n",
    "\n",
    "<span t=\"l2\">$d_{Manh}(x,y)=\\sum_{i=1}^{n} | y_i-x_i |$</span>\n",
    "\n",
    "<span t=\"l1\">Odległość (metryka) Minkowskiego</span>\n",
    "\n",
    "<span t=\"l2\">$d_{Mink}(x,y)=\\sqrt[q]{\\sum_{i=1}^{n} | y_i-x_i |^q} $</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b6ee2",
   "metadata": {},
   "source": [
    "<span t=\"l1\">Dla atrybutów symbolicznych możemy zdefiniować funkcję R („różne od”).</span>\n",
    "\n",
    "<span t=\"l1\">Dla $i$-tego atrybutu funkcja ma postać: </span>\n",
    "\n",
    "<span t=\"l2\">\n",
    "$R(x_i,y_i)=\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "0&\\mbox{dla}&x_i=y_i\\\\\n",
    "1&\\mbox{dla}&\\mbox{w przeciwnym przypadku}\n",
    "\\end{array}\n",
    "\\right.$</span>\n",
    "\n",
    "<span t=\"l1\">Funkcja $R$ może zostać zastosowana dla i-tego atrubutu w miarach odległości.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a84854",
   "metadata": {},
   "source": [
    "### Normalizacja wartości atrybutów\n",
    "\n",
    "<span t=\"l1\">Przy wyznaczaniu odległości atrybuty posiadające duże wartości mogą niwelować wpływ innych atrybutów (tych posiadających mniejsze wartości).</span>\n",
    "\n",
    "<span t=\"l1\">W celu wyeliminowania tej sytuacji należy dokonać normalizacji wartości atrybutów.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1159e943",
   "metadata": {},
   "source": [
    "<span t=\"l1\">Normalizacja min-max</span>\n",
    "\n",
    "- <span t=\"l2\">Dla zbioru wartości atrybutu: $X=\\{x_1,x_2,...,x_k\\}$</span>\n",
    "\n",
    "<span t=\"l1\">Znormalizowanawartość $x_i$ jest obliczana jako:</span> \n",
    "- <span t=\"l2\">$x_i^{*}=\\frac{x_i- min (X)}{zakres(X)}= \\frac{x_i- min (X)}{max(X)-min(X)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7dd95f",
   "metadata": {},
   "source": [
    "### Algorytmy iteracyjnej optymalizacji\n",
    "\n",
    "<span t=\"l1\">W algorytmach iteracyjnej optymalizacji najlepszy podział zbioru przypadków jest wyznaczany przez iteracyjne polepszanie pewnych wskaźników jakości, startując z początkowego, najczęściej losowego, podziału.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118ac91",
   "metadata": {},
   "source": [
    "### Mrówkowe algorytmy grupowania\n",
    "\n",
    "Zaletą mrówkowych algorytmów grupowania jest brak konieczności określania a priori liczby grup, na które zbiór przypadków jest dzielony.\n",
    "\n",
    "Mrówkowe algorytmy grupowania są głównie oparte na wersjach zaproponowanych przez:\n",
    "- Jean-Louisa Deneubourga, \n",
    "- Erika Lumera i Baldo Faieta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ccec3",
   "metadata": {},
   "source": [
    "### Mrówkowy algorytm grupowania - przykład\n",
    "\n",
    "<span t=\"l1\">Funkcja sąsiedztwa</span>\n",
    "\n",
    "<span t=\"l2\">\n",
    "$f_n(x_i)=\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "\\frac{1}{\\sigma^2} \\sum_{j \\in N} ( 1-\\frac{d(x_i,x_j)}{\\alpha})&\\mbox{jeśli}&\\forall_{j \\in N}( 1-\\frac{d(x_i,x_j)}{\\alpha})>0 \\\\\n",
    "0&\\mbox{   }&\\mbox{w przeciwnym przypadku}\n",
    "\\end{array}\n",
    "\\right.$</span>\n",
    "\n",
    "- $N$ – sąsiedztwo $i$-tego obiektu\n",
    "- $\\sigma$ - rozmiar sąsiedztwa $N$\n",
    "- $\\alpha$ - parametr definiujący skalę niepodobieństwa obiektów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e23cb6",
   "metadata": {},
   "source": [
    "<span t=\"l1\">Prawdopodobieństwo podniesienia obiektu:</span>\n",
    "\n",
    "<span t=\"l2\">\n",
    "$p_{pick}(x_i)=\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "1&\\mbox{jeśli}&f_{n}(x_i) \\leq 1 \\\\\n",
    "\\frac{1}{f^2_{n}(x_i)}&\\mbox{   }&\\mbox{w przeciwnym przypadku}\n",
    "\\end{array}\n",
    "\\right.$</span>\n",
    "\n",
    "\n",
    "<span t=\"l1\">Prawdopodobieństwo upuszczenia obiektu:</span>\n",
    "\n",
    "<span t=\"l2\">\n",
    "$p_{pick}(x_i)=\\left\\{\n",
    "\\begin{array}{ccc}\n",
    "1&\\mbox{jeśli}&f_{n}(x_i) \\geq 1 \\\\\n",
    "\\frac{1}{f^4_{n}(x_i)}&\\mbox{   }&\\mbox{w przeciwnym przypadku}\n",
    "\\end{array}\n",
    "\\right.$</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c44705",
   "metadata": {},
   "source": [
    "### Algorytm\n",
    "- losowo ustaw obiekty (przypadki) na siatce prostokątnej\n",
    "- dla każdej mrówki $a_j$:\n",
    "    – losowo wybierz obiekt $x_i$\n",
    "    - ustaw obiekt $x_i$ jako niesiony przez mrówkę $a_j$\n",
    "    - ustaw mrówkę $a_j$ na losowo wybranej pustej pozycji na siatce prostokątnej\n",
    "    \n",
    "- dla każdej iteracji $t$ od $1$ do $t_{max}$: \n",
    "    - losowo wybierz mrówkę $a_j$\n",
    "    - przesuń mrówkę $a_j$ na losowo wybraną nową pozycję na siatce prostokątnej\n",
    "    - oblicz prawdopodobieństwo upuszczenia obiektu niesionego przez mrówkę $a_j$    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff9e2c8",
   "metadata": {},
   "source": [
    "- jeśli obiekt zostanie upuszczony przez mrówkę $a_j$\n",
    "    - dopóki mrówka $a_j$ nie niesie żadnego obiektu\n",
    "        - losowo wybierz obiekt $x_i$\n",
    "        - oblicz prawdopodobieństwo podniesienia obiektu $x_i$ przez mrówkę $a_j$\n",
    "    - jeśli mrówka podniesie obiekt $x_i$\n",
    "        - ustaw obiekt $x_i$ jako niesiony przez mrówkę $a_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aeefcb",
   "metadata": {},
   "source": [
    "### Mrówkowe algorytmy grupowania\n",
    "\n",
    "Podstawowy mrówkowy algorytm grupowania wykorzystuje losowe przemieszczanie się mrówek na siatce prostokątnej.\n",
    "\n",
    "W określaniu przemieszczania się mrówek może zostać wykorzystany mechanizm feromonów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d2127",
   "metadata": {},
   "source": [
    "Prawdopodobieństwo przejścia mrówki $z$ komórki $i$ do komórki $k$:\n",
    "\n",
    "$p_{i \\to k}= \\frac{W(\\varphi_k)w(\\Delta_k)}{\\sum_{j \\in N} W(\\varphi_j)w(\\Delta_j) } $ \n",
    "\n",
    "- $N$ – sąsiedztwo komórki i\n",
    "- $\\varphi$ – parametr powiązany z natężeniem feromonu\n",
    "- $\\Delta$ – parametr powiązany z różnicą w orientacji mrówek w kolejnych iteracjach \n",
    "- $W, w$ – funkcje wagowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf7dcd",
   "metadata": {},
   "source": [
    "## Optymalizacja rojem cząstek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb28699",
   "metadata": {},
   "source": [
    "### Optymalizacja rojem cząstek\n",
    "\n",
    "Optymalizacja rojem cząstek (ang. *Particle Swarm Optimization*, *PSO*) jest metodą poszukiwania najlepszego rozwiązania w N wymiarowej przestrzeni rozwiązań.\n",
    "\n",
    "Optymalizacja rojem cząstek została zaproponowana przez Russella Eberharta i Jamesa Kennedy'ego w 1995 roku.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa854bd",
   "metadata": {},
   "source": [
    "Najlepsze rozwiązanie poszukiwane jest przez zbiór cząstek lecących jak rój przez przestrzeń rozwiązań.\n",
    "\n",
    "Poprzez analogię do stada ptaków podążającego za przywódcą, rój cząstek podąża za najlepszym do tej pory znalezionym rozwiązaniem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6efd47",
   "metadata": {},
   "source": [
    "Każda i-ta cząstka traktowana jest jako punkt w N wymiarowej przestrzeni rozwiązań opisany przez wektor współrzędnych:\n",
    "- $X^i=(x^i_{1}, x^i_{2}, \\dots , x^i_{N})$\n",
    "\n",
    "Dla każdej i-tej cząstki pamiętana jest jako wektor najlepsza do tej pory znaleziona pozycja (pozycja, dla której funkcja dopasowania miała największą wartość):\n",
    "\n",
    "- $P^i=(p^i_{1}, p^i_{2}, \\dots , p^i_{N})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa068e",
   "metadata": {},
   "source": [
    "Pamiętana jest jako wektor globalnie najlepsza do tej pory znaleziona pozycja:\n",
    "- $G=(g_{1}, g_{2}, \\dots , g_{N})$\n",
    "\n",
    "Z każdą $i$-tą cząstka powiązany jest wektor jej prędkości:\n",
    "- $V^i=(v^i_{1}, v^i_{2}, \\dots , v^i_{N})$\n",
    "\n",
    "Na początku wektory pozycji cząstek oraz wektory ich prędkości inicjalizowane są losowo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c34569",
   "metadata": {},
   "source": [
    "W każdym kroku algorytmu iteracyjnego modyfikowane są wektory: pozycji cząstek oraz prędkości cząstek zgodnie z zależnościami:\n",
    "- $v^i_{j}(t+1)=\\omega v^i_{j}(t)+\\psi_1 R_1 (p^i_{j}(t)-x^i_{j}(t))+\\psi_2 R_2 (g_{j}(t)-x^i_{j}(t))$\n",
    "\n",
    "- $\\omega, \\psi_1, \\psi_2$ – stałe\n",
    "- $R_1$, $R_2$ – dwa wektory wartości losowych z przedziału $[0,1]$\n",
    "- generowane niezależnie w każdej iteracji dla każdej cząstki $j=1,2,...,N$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c63ca4",
   "metadata": {},
   "source": [
    "Warunkiem zakończenia algorytmu iteracyjnego może być:\n",
    "- osiągnięcie odpowiednio dużej wartość funkcji dopasowania,\n",
    "- osiągnięcie maksymalnej liczby iteracji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf5c53a",
   "metadata": {},
   "source": [
    "- Inteligencja stadna realizowana jest przez pamiętanie globalnie najlepszej do tej pory znalezionej pozycji G.\n",
    "- Wartości współrzędnych pozycji G uwzględniane są przy wyznaczaniu nowych wartości w wektorach pozycji oraz prędkości cząstek.\n",
    "- W porównaniu z obliczeniami ewolucyjnymi w optymalizacji rojem cząstek nie występuje proces selekcji. Wszystkie cząstki biorą udział w poszukiwaniu najlepszego rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a5c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
